# ScraperShorts

A full-stack application for scraping, managing, and displaying images from dynamic websites. Built with FastAPI backend, Next.js frontend, MongoDB database, and Cloudflare R2 storage.

## ğŸ“‹ Table of Contents

- [Project Overview](#project-overview)
- [Tech Stack](#tech-stack)
- [Architecture](#architecture)
- [Project Structure](#project-structure)
- [Prerequisites](#prerequisites)
- [Installation & Setup](#installation--setup)
- [Backend Setup](#backend-setup)
- [Frontend Setup](#frontend-setup)
- [Configuration](#configuration)
- [API Documentation](#api-documentation)
- [Features](#features)
- [Database Schema](#database-schema)
- [Deployment](#deployment)
- [Development](#development)
- [Testing](#testing)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Project Overview

ScraperShorts is a comprehensive web scraping and image management platform designed to:

- Dynamically scrape images from websites using Selenium WebDriver
- Store and manage scraped images efficiently in MongoDB
- Upload images to Cloudflare R2 for CDN delivery
- Provide a RESTful API for image operations
- Display images in an interactive Next.js frontend with advanced filtering and search capabilities
- Support user authentication and personalized galleries
- Generate statistics and analytics about scraped content

## ğŸ› ï¸ Tech Stack

### Backend
- **Framework:** FastAPI 0.104.1
- **Server:** Uvicorn 0.24.0
- **Web Scraping:** Selenium 4.15.2
- **Database:** MongoDB with Motor 3.3.2 (async driver)
- **Validation:** Pydantic 2.4.2
- **Cloud Storage:** Cloudflare R2
- **Authentication:** Python-Jose with JWT, Passlib with Bcrypt
- **HTTP Client:** HTTPX 0.25.1
- **Logging:** Loguru 0.7.2
- **Testing:** Pytest 7.4.3, Pytest-asyncio, Pytest-cov

### Frontend
- **Framework:** Next.js 15.2.4
- **UI Library:** React 19
- **Styling:** Tailwind CSS
- **Component Library:** Radix UI
- **Type Safety:** TypeScript
- **State Management:** React Context API
- **Form Handling:** React Hook Form
- **Icons:** Lucide React
- **Theme Management:** Next-themes

### Infrastructure
- **Database:** MongoDB
- **Object Storage:** Cloudflare R2
- **Web Server:** FastAPI/Uvicorn

## ğŸ“ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Frontend (Next.js)                      â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚        â”‚  - Image Gallery with filtering          â”‚         â”‚
â”‚        â”‚  - User Authentication                    â”‚         â”‚
â”‚        â”‚  - Search & Navigation                    â”‚         â”‚
â”‚        â”‚  - Theme Support                          â”‚         â”‚
â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                    HTTP API (REST)
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Backend (FastAPI)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  API Routes     â”‚  â”‚   Scraper Engine                 â”‚  â”‚
â”‚  â”‚  - Images CRUD  â”‚  â”‚  - Selenium WebDriver            â”‚  â”‚
â”‚  â”‚  - Auth         â”‚  â”‚  - BeautifulSoup parsing         â”‚  â”‚
â”‚  â”‚  - Stats        â”‚  â”‚  - Dynamic page handling         â”‚  â”‚
â”‚  â”‚  - Search       â”‚  â”‚  - Image download & processing   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Cloud Storage  â”‚  â”‚   Database Layer                 â”‚  â”‚
â”‚  â”‚  - Cloudflare R2â”‚  â”‚  - MongoDB connection            â”‚  â”‚
â”‚  â”‚  - Upload/Sync  â”‚  â”‚  - Async queries                 â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                   â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Cloudflareâ”‚                  â”‚  MongoDB    â”‚
    â”‚    R2     â”‚                  â”‚             â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“‚ Project Structure

```
ScraperShorts/
â”œâ”€â”€ Backend/                          # FastAPI backend application
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                  # FastAPI app initialization
â”‚   â”‚   â”œâ”€â”€ config.py                # Configuration & settings
â”‚   â”‚   â”œâ”€â”€ database.py              # MongoDB connection & queries
â”‚   â”‚   â”œâ”€â”€ models.py                # Pydantic data models
â”‚   â”‚   â”œâ”€â”€ cloudflare_r2.py        # R2 storage integration
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ routes.py            # API endpoint definitions
â”‚   â”‚   â””â”€â”€ scraper/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ base_scraper.py      # Abstract base scraper class
â”‚   â”‚       â””â”€â”€ selenium_scraper.py  # Selenium implementation
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ test_api.py              # API unit tests
â”‚   â”œâ”€â”€ images/                      # Local image storage
â”‚   â”œâ”€â”€ migrate_images_to_r2.py      # Migration script
â”‚   â”œâ”€â”€ delete_all_r2_images.py      # Cleanup script
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â””â”€â”€ README.md                    # Backend documentation
â”‚
â””â”€â”€ Frontend/                         # Next.js frontend application
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ layout.tsx               # Root layout
    â”‚   â”œâ”€â”€ page.tsx                 # Home page
    â”‚   â”œâ”€â”€ loading.tsx              # Loading state
    â”‚   â”œâ”€â”€ globals.css              # Global styles
    â”‚   â””â”€â”€ scrape/
    â”‚       â””â”€â”€ page.tsx             # Scraping interface
    â”œâ”€â”€ components/
    â”‚   â”œâ”€â”€ category-nav.tsx         # Category navigation
    â”‚   â”œâ”€â”€ filter-dropdown.tsx       # Filter controls
    â”‚   â”œâ”€â”€ image-card.tsx           # Image display card
    â”‚   â”œâ”€â”€ image-gallery.tsx        # Gallery grid
    â”‚   â”œâ”€â”€ image-modal.tsx          # Image details modal
    â”‚   â”œâ”€â”€ login-modal.tsx          # Login form
    â”‚   â”œâ”€â”€ signup-modal.tsx         # Registration form
    â”‚   â”œâ”€â”€ search-bar.tsx           # Search interface
    â”‚   â”œâ”€â”€ sidebar.tsx              # Navigation sidebar
    â”‚   â”œâ”€â”€ stats-panel.tsx          # Statistics display
    â”‚   â”œâ”€â”€ theme-toggle.tsx         # Dark/light mode
    â”‚   â”œâ”€â”€ gallery-context.tsx      # Global state management
    â”‚   â””â”€â”€ ui/                      # Shadcn/ui components
    â”œâ”€â”€ hooks/
    â”‚   â”œâ”€â”€ useImages.ts             # Custom hook for image operations
    â”‚   â”œâ”€â”€ useScraper.ts            # Custom hook for scraping
    â”‚   â”œâ”€â”€ use-media-query.ts       # Responsive design
    â”‚   â”œâ”€â”€ use-mobile.tsx           # Mobile detection
    â”‚   â””â”€â”€ use-toast.ts             # Toast notifications
    â”œâ”€â”€ lib/
    â”‚   â”œâ”€â”€ api-config.ts            # API configuration
    â”‚   â”œâ”€â”€ api-service.ts           # API client wrapper
    â”‚   â””â”€â”€ utils.ts                 # Utility functions
    â”œâ”€â”€ public/                      # Static assets
    â”œâ”€â”€ styles/                      # Additional stylesheets
    â”œâ”€â”€ package.json                 # NPM dependencies
    â”œâ”€â”€ next.config.mjs              # Next.js configuration
    â”œâ”€â”€ tailwind.config.ts           # Tailwind CSS config
    â”œâ”€â”€ tsconfig.json                # TypeScript configuration
    â””â”€â”€ components.json              # Shadcn/ui config
```

## ğŸ“¦ Prerequisites

### System Requirements
- **Node.js:** 18.x or higher
- **Python:** 3.8 or higher
- **MongoDB:** 4.x or higher
- **Browser:** Chrome or Firefox (for Selenium)
- **Cloudflare Account:** For R2 storage (optional)

### Environment Variables
Before running the application, ensure you have:
- MongoDB URI
- Cloudflare R2 credentials (if using cloud storage)
- CORS origins configuration
- API configuration details

## ğŸš€ Installation & Setup

### Clone the Repository

```bash
git clone <repository-url>
cd ScraperShorts
```

## ğŸ”§ Backend Setup

### 1. Create Virtual Environment

```bash
cd Backend
python -m venv venv

# On Windows
venv\Scripts\activate

# On macOS/Linux
source venv/bin/activate
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Create `.env` File

Create a `.env` file in the `Backend/` directory:

```env
# Application
APP_NAME=ScraperShorts
DEBUG=False
ENVIRONMENT=development
API_V1_STR=/api/v1

# MongoDB
MONGODB_URL=mongodb://localhost:27017
MONGODB_DB_NAME=scrapershorts

# Selenium
SELENIUM_HEADLESS=true
SELENIUM_TIMEOUT=30
SELENIUM_SCROLL_DELAY=1.0
SELENIUM_DRIVER_PATH=/path/to/chromedriver  # Optional

# Image Storage
IMAGE_STORAGE_PATH=images
MAX_IMAGES_PER_SCRAPE=100

# Cloudflare R2
R2_ACCOUNT_ID=your_account_id
R2_ACCESS_KEY_ID=your_access_key
R2_SECRET_ACCESS_KEY=your_secret_key
R2_BUCKET_NAME=scrapershorts
R2_ENDPOINT_URL=https://<account-id>.r2.cloudflarestorage.com

# CORS
CORS_ORIGINS=["http://localhost:3000", "http://localhost:8000"]

# Logging
LOG_LEVEL=INFO
LOG_FILE=app.log
```

### 4. Install WebDriver

Download the appropriate webdriver:
- **Chrome:** [ChromeDriver](https://chromedriver.chromium.org/)
- **Firefox:** [GeckoDriver](https://github.com/mozilla/geckodriver)

### 5. Start MongoDB

```bash
# Using Docker (recommended)
docker run -d -p 27017:27017 --name mongodb mongo:latest

# Or use your local MongoDB installation
```

### 6. Run Backend Server

```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

Backend will be available at `http://localhost:8000`

## ğŸ¨ Frontend Setup

### 1. Navigate to Frontend Directory

```bash
cd Frontend
```

### 2. Install Dependencies

```bash
npm install
```

### 3. Create `.env.local` File

Create a `.env.local` file in the `Frontend/` directory:

```env
NEXT_PUBLIC_API_URL=http://localhost:8000/api/v1
NEXT_PUBLIC_IMAGE_BASE_URL=http://localhost:8000/images
```

### 4. Run Development Server

```bash
npm run dev
```

Frontend will be available at `http://localhost:3000`

### 5. Build for Production

```bash
npm run build
npm start
```

## âš™ï¸ Configuration

### Backend Configuration (`Backend/app/config.py`)

| Setting | Default | Description |
|---------|---------|-------------|
| `APP_NAME` | ScraperShorts | Application name |
| `DEBUG` | False | Debug mode toggle |
| `ENVIRONMENT` | development | Environment (development/production) |
| `MONGODB_URL` | mongodb://localhost:27017 | MongoDB connection string |
| `MONGODB_DB_NAME` | scrapershorts | Database name |
| `SELENIUM_HEADLESS` | True | Run browser headless |
| `SELENIUM_TIMEOUT` | 30 | Timeout for page loads (seconds) |
| `SELENIUM_SCROLL_DELAY` | 1.0 | Delay between scroll actions |
| `MAX_IMAGES_PER_SCRAPE` | 100 | Maximum images per scrape task |
| `CORS_ORIGINS` | ["http://localhost:3000"] | Allowed origins |

### Frontend Configuration

Environment variables in `Frontend/.env.local`:

| Variable | Description |
|----------|-------------|
| `NEXT_PUBLIC_API_URL` | Backend API base URL |
| `NEXT_PUBLIC_IMAGE_BASE_URL` | Image storage base URL |

## ğŸ“¡ API Documentation

### Base URL
```
http://localhost:8000/api/v1
```

### Main Endpoints

#### Image Management

**GET** `/images`
- Retrieve all images with filtering and pagination
- Query Parameters:
  - `skip`: Offset (default: 0)
  - `limit`: Items per page (default: 10)
  - `category`: Filter by category
  - `tags`: Filter by tags (comma-separated)
  - `search`: Full-text search

**GET** `/images/{image_id}`
- Get single image details

**POST** `/images`
- Create image manually
- Body: `ImageCreate` schema

**PUT** `/images/{image_id}`
- Update image metadata

**DELETE** `/images/{image_id}`
- Delete image

#### Scraping

**POST** `/scrape`
- Start background scraping task
- Body:
  ```json
  {
    "category": "nature",
    "max_images": 50,
    "url": "https://example.com",
    "tags": ["landscape", "outdoor"]
  }
  ```
- Response:
  ```json
  {
    "task_id": "uuid",
    "status": "processing",
    "message": "Scraping started"
  }
  ```

**GET** `/scrape/status/{task_id}`
- Get scraping task status

#### Statistics

**GET** `/stats`
- Get overall statistics
- Returns:
  ```json
  {
    "total_images": 1000,
    "top_tags": [{"tag": "nature", "count": 250}],
    "source_breakdown": [{"source": "site.com", "count": 500}],
    "last_scraped": "2024-01-15T10:30:00"
  }
  ```

#### Search

**GET** `/search`
- Full-text search across images
- Query Parameters:
  - `q`: Search query
  - `limit`: Results limit

#### Cloud Storage

**POST** `/upload-to-r2/{image_id}`
- Upload image to Cloudflare R2

**GET** `/r2-url/{image_id}`
- Get R2 CDN URL for image

## ğŸ¨ Features

### Backend Features
- âœ… Dynamic web scraping with Selenium
- âœ… Asynchronous image downloading
- âœ… MongoDB integration with async driver
- âœ… RESTful API with comprehensive endpoints
- âœ… Background task management
- âœ… JWT authentication (prepared)
- âœ… Image processing and optimization
- âœ… Cloudflare R2 integration
- âœ… Comprehensive error handling
- âœ… Structured logging with loguru
- âœ… CORS support
- âœ… Data validation with Pydantic

### Frontend Features
- âœ… Responsive image gallery
- âœ… Advanced filtering (category, tags)
- âœ… Full-text search
- âœ… Dark/Light theme support
- âœ… Image modal with detailed view
- âœ… Mobile-responsive design
- âœ… User authentication UI
- âœ… Statistics dashboard
- âœ… Manual scraping interface
- âœ… Toast notifications
- âœ… Loading states
- âœ… Accessibility support (Radix UI)

## ğŸ“Š Database Schema

### Images Collection

```javascript
{
  _id: ObjectId,
  title: String,
  image_url: String,
  source_url: String,
  local_path: String,
  r2_url: String,           // Cloudflare R2 URL
  category: String,
  tags: [String],
  scraped_at: DateTime,
  created_at: DateTime,
  updated_at: DateTime,
  metadata: {
    width: Number,
    height: Number,
    size: Number,
    format: String
  }
}
```

### Indexes
```javascript
// Recommended indexes for performance
db.images.createIndex({ category: 1 })
db.images.createIndex({ tags: 1 })
db.images.createIndex({ scraped_at: -1 })
db.images.createIndex({ title: "text", tags: "text" })
```

## ğŸš¢ Deployment

### Docker Deployment (Recommended)

#### Backend Dockerfile

```dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY app/ ./app/

CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### Frontend Dockerfile

```dockerfile
FROM node:18-alpine AS builder

WORKDIR /app
COPY package*.json ./
RUN npm ci
COPY . .
RUN npm run build

FROM node:18-alpine

WORKDIR /app
COPY --from=builder /app/.next ./.next
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package*.json ./
COPY public ./public

CMD ["npm", "start"]
```

#### Docker Compose

```yaml
version: '3.8'

services:
  mongodb:
    image: mongo:latest
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db

  backend:
    build: ./Backend
    ports:
      - "8000:8000"
    environment:
      - MONGODB_URL=mongodb://mongodb:27017
      - ENVIRONMENT=production
    depends_on:
      - mongodb

  frontend:
    build: ./Frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://backend:8000/api/v1

volumes:
  mongodb_data:
```

### Cloud Deployment

#### Vercel (Frontend)
1. Push code to GitHub
2. Import project on Vercel
3. Set environment variables
4. Deploy

#### Heroku/Railway (Backend)
1. Create Procfile:
   ```
   web: uvicorn app.main:app --host 0.0.0.0 --port $PORT
   ```
2. Deploy using platform CLI

## ğŸ”¨ Development

### Local Development Environment

1. **Install additional dev tools:**
   ```bash
   pip install black flake8 isort
   npm install --save-dev prettier eslint
   ```

2. **Code formatting:**
   ```bash
   # Backend
   black Backend/
   isort Backend/
   
   # Frontend
   npm run lint
   prettier --write Frontend/
   ```

3. **Run with hot-reload:**
   ```bash
   # Backend
   uvicorn app.main:app --reload
   
   # Frontend
   npm run dev
   ```

### Project Setup for Contributors

```bash
# Clone repo
git clone <repo-url>
cd ScraperShorts

# Backend setup
cd Backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# Frontend setup
cd ../Frontend
npm install

# Create env files
# .env in Backend/ with MongoDB and Cloudflare credentials
# .env.local in Frontend/ with API URLs
```

## ğŸ§ª Testing

### Backend Tests

```bash
cd Backend
pytest tests/ -v                    # Run all tests
pytest tests/test_api.py -v        # Run specific test file
pytest tests/ --cov                # With coverage report
pytest tests/ --cov --cov-report=html  # HTML coverage report
```

### Frontend Tests

```bash
cd Frontend
npm test                    # Run tests
npm run test:coverage      # With coverage
```

### Running Tests with Coverage

```bash
# Backend
pytest --cov=app --cov-report=html tests/

# Frontend (if configured)
npm test -- --coverage
```

## ğŸ“ Maintenance Scripts

### Migrate Images to Cloudflare R2

```bash
python Backend/migrate_images_to_r2.py
```

Uploads all local images to Cloudflare R2 and updates database with R2 URLs.

### Delete All R2 Images

```bash
python Backend/delete_all_r2_images.py
```

âš ï¸ **Warning:** This permanently deletes all images from R2 bucket.

## ğŸ› Troubleshooting

### Common Issues

**MongoDB Connection Error**
```
Solution: Ensure MongoDB is running and MONGODB_URL is correct
docker run -d -p 27017:27017 mongo:latest
```

**Selenium WebDriver Issues**
```
Solution: Download correct chromedriver for your OS
export SELENIUM_DRIVER_PATH=/path/to/chromedriver
```

**CORS Errors in Frontend**
```
Solution: Add frontend URL to CORS_ORIGINS in .env
CORS_ORIGINS=["http://localhost:3000"]
```

**R2 Upload Failures**
```
Solution: Verify R2 credentials and bucket name
Check Cloudflare dashboard for correct credentials
```

## ğŸ“š Additional Resources

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Next.js Documentation](https://nextjs.org/docs)
- [MongoDB Manual](https://docs.mongodb.com/manual/)
- [Selenium Documentation](https://selenium.dev/documentation/)
- [Cloudflare R2 Guide](https://developers.cloudflare.com/r2/)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [Tailwind CSS](https://tailwindcss.com/docs)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see LICENSE file for details.

## ğŸ‘¥ Support

For support, email support@scrapershorts.com or open an issue on GitHub.

## ğŸ¯ Roadmap

- [ ] Advanced authentication (OAuth, social login)
- [ ] Real-time scraping progress via WebSocket
- [ ] Image recognition and auto-tagging
- [ ] Batch processing and scheduling
- [ ] Advanced analytics dashboard
- [ ] API rate limiting and quotas
- [ ] Multi-language support
- [ ] Mobile app (React Native)
- [ ] Scraper plugins system
- [ ] Performance optimization

---

**Last Updated:** December 2024  
**Version:** 1.0.0
